---
title: "HW6"
author: "Wes Bonelli"
output: html_notebook
---

## 1.

```{r}
proficiency = read.table('proficiency.txt', header = T, sep = '')
proficiency$TM <- as.factor(proficiency$TM)
proficiency_no_tm = proficiency[1:length(proficiency)-1]
```

### 1a.

```{r}
stem(proficiency_no_tm$E1)
stem(proficiency_no_tm$E2)
stem(proficiency_no_tm$E3)
stem(proficiency_no_tm$E4)
```

From the stem-and-leaf plots we see that E1, E2, and E3 are unimodal while E4 appears to be bimodal. E1 and E3 seem roughly normal while E2 skews negative.

### 1b.

```{r}
pairs(proficiency_no_tm)
library(corrplot)
proficiency_no_tm_cor = cor(proficiency_no_tm)
corrplot(proficiency_no_tm_cor)
```
E3 and E4 scores show a strong positive correlation with job performance rating, and are also correlated with one another, though it's unclear whether the correlation is large enough to produce collinearity problems.

### 1c.

```{r}
proficiency_model_no_tm = lm(JPR ~ E1 + E2 + E3 + E4, data = proficiency_no_tm)
summary(proficiency_model_no_tm)
```

### 1d.

As can be seen from the model summary, E1, E3, and E4 are significant terms, while E2 is just above the $\alpha$ = 0.05 significance threshold.

```{r}
library(car)
vif(proficiency_model_no_tm)
```

As observed above, no pairs of independent variables show enough collinearity to provoke serious concern (variance inflation factors are all less than 10). Thus the best model is likely:

```{r}
proficiency_model_no_tm_best = lm(JPR ~ E1 + E3 + E4, data = proficiency_no_tm)
summary(proficiency_model_no_tm_best)
```


### 1e.

```{r}
library('ggplot2')
proficiency_coefficients = coef(proficiency_model_no_tm)
proficiency_no_tm$predicted = predict(proficiency_model_no_tm)
proficiency_no_tm$residuals = residuals(proficiency_model_no_tm)
ggplot(proficiency_no_tm, aes(x = E1, y = JPR)) +
  geom_segment(aes(xend = E1, yend = predicted), alpha = .2) +
  geom_point(aes(size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency_no_tm, aes(x = E2, y = JPR)) +
  geom_segment(aes(xend = E2, yend = predicted), alpha = .2) +
  geom_point(aes(size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency_no_tm, aes(x = E3, y = JPR)) +
  geom_segment(aes(xend = E3, yend = predicted), alpha = .2) +
  geom_point(aes(size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency_no_tm, aes(x = E4, y = JPR)) +
  geom_segment(aes(xend = E4, yend = predicted), alpha = .2) +
  geom_point(aes(size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
library(magrittr)
library(tidyr)
proficiency_no_tm %>% 
  gather(key = "iv", value = "score", -JPR, -predicted, -residuals) %>%
  ggplot(aes(x = score, y = JPR)) +
  geom_segment(aes(xend = score, yend = predicted), alpha = .2) +
  geom_point(aes(size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  facet_grid(rows = vars(iv), scales = 'fixed', as.table = TRUE) +
  theme_bw()
```

Applicants with marginally higher scores than predicted are show in lighter blue, while those with marginally lower scores are shown in darker blue. Residual magnitude is indicated by the size of point.

### 1f.

```{r}
proficiency_model = lm(JPR ~ E1 + E2 + E3 + E4 + factor(TM), data = proficiency)
summary(proficiency_model)
proficiency_coefficients = coef(proficiency_model)
proficiency$predicted = predict(proficiency_model)
proficiency$residuals = residuals(proficiency_model)
ggplot(proficiency, aes(x = E1, y = JPR)) +
  geom_segment(aes(xend = E1, yend = predicted), alpha = .2) +
  geom_point(aes(shape = TM, size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency, aes(x = E2, y = JPR)) +
  geom_segment(aes(xend = E2, yend = predicted), alpha = .2) +
  geom_point(aes(shape = TM, size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency, aes(x = E3, y = JPR)) +
  geom_segment(aes(xend = E3, yend = predicted), alpha = .2) +
  geom_point(aes(shape = TM, size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(proficiency, aes(x = E4, y = JPR)) +
  geom_segment(aes(xend = E4, yend = predicted), alpha = .2) +
  geom_point(aes(shape = TM, size = abs(residuals), color = residuals, alpha = .3)) +
  guides(color = FALSE, size = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
library(magrittr)
library(tidyr)
proficiency %>% 
  gather(key = "iv", value = "score", -JPR, -predicted, -residuals, -TM) %>%
  ggplot(aes(x = score, y = JPR)) +
  geom_segment(aes(xend = score, yend = predicted), alpha = .2) +
  geom_point(aes(shape = TM, size = abs(residuals), alpha = .3)) +
  guides(color = FALSE, size = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  facet_grid(rows = vars(iv), scales = 'fixed', as.table = TRUE) +
  theme_bw()
```

Applicants with marginally higher scores than predicted are show in lighter blue, while those with marginally lower scores are shown in darker blue. Residual magnitude is indicated by the size of point. Time of hiring is indicated by shape. From the model summary we can see that time of hiring is associated with a p-value of 0.7618, thus there is not evidence that TM affects JPR. This is reflected in the plots: circles and triangles seem approximately equally distributed with respect to the vertical axis.

## 2.

```{r}
gradrec = read.table('gradrec.txt', header = T, sep = '')
```

### 2a.

```{r}
gradrec$IP = ifelse(gradrec$DG == 'P', 1, 0)
gradrec$IF = ifelse(gradrec$SX == 'F', 1, 0)
gradrec_model = lm(SCORE ~ E1 + E2 + GPA + IP + IF, data = gradrec)
summary(gradrec_model)
vif(gradrec_model)
gradrec_coefficients = coef(gradrec_model)
gradrec$predicted = predict(gradrec_model)
gradrec$residuals = residuals(gradrec_model)
ggplot(gradrec, aes(x = E1, y = SCORE)) +
  geom_segment(aes(xend = E1, yend = predicted), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = E2, y = SCORE)) +
  geom_segment(aes(xend = E2, yend = predicted), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = GPA, y = SCORE)) +
  geom_segment(aes(xend = GPA, yend = predicted), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = IP, y = SCORE)) +
  geom_segment(aes(xend = IP, yend = predicted), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = IF, y = SCORE)) +
  geom_segment(aes(xend = IF, yend = predicted), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted), shape = 1) +
  theme_bw()
```

None of the variables are sufficiently collinear to cause concern, and the clear linear trends in the predictors E1, E2, and GPA suggests that a polynomial model is unnecessary. The full model with no additional polynomial terms is likely the best if we must use all 5 predictors.

This model's $R^2$ = 0.9577.

### 2b.

```{r}
gradrec_predictions = predict(
  gradrec_model,
  newdata = data.frame(E1=c(75), E2=c(69), GPA=c(3.75), IP=c(0), IF=c(1)),
  se.fit = T)
paste(
  gradrec_predictions$fit - (1.96 * gradrec_predictions$se.fit),
  gradrec_predictions$fit + (1.96 * gradrec_predictions$se.fit))
```

The 95% confidence interval is approx. [74.22, 75.75].

### 2c.

```{r}
paste(
  gradrec_predictions$fit - (1.64 * gradrec_predictions$se.fit),
  gradrec_predictions$fit + (1.64 * gradrec_predictions$se.fit))
```

The 90% confidence interval is approx. [74.35, 75.62].

### 2d.


As seen above, GPA and scores on Exams 1 and 2 are significantly associated with overall score. Master's/PhD status and sex, on the other hand, can be discarded at $\alpha = 0.1$, even though degree status does seem to be slightly associated with score. None of the variables are sufficiently collinear to cause concern, and the clear linear trends in the other predictors suggests that a polynomial model is unnecessary. The best model is likely:

```{r}
gradrec_model_best = lm(SCORE ~ E1 + E2 + GPA, data = gradrec)
summary(gradrec_model_best)
```

### 2e.

```{r}
gradrec_coefficients_best = coef(gradrec_model_best)
gradrec$predicted_best = predict(gradrec_model_best)
gradrec$residuals_best = residuals(gradrec_model_best)
ggplot(gradrec, aes(x = E1, y = SCORE)) +
  geom_segment(aes(xend = E1, yend = predicted_best), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted_best), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = E2, y = SCORE)) +
  geom_segment(aes(xend = E2, yend = predicted_best), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted_best), shape = 1) +
  theme_bw()
ggplot(gradrec, aes(x = GPA, y = SCORE)) +
  geom_segment(aes(xend = GPA, yend = predicted_best), alpha = .2) +
  geom_point(aes(color = residuals)) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red") +
  guides(color = FALSE, size = FALSE, shape = FALSE, alpha = FALSE) +
  geom_point(aes(y = predicted_best), shape = 1) +
  theme_bw()
```

### 2f.

```{r}
table(gradrec[5:6])
```

In this department it seems male and female students are about equally likely to go on to a PhD.

### 2g.

The models are so different because exam scores and GPA predict student rating much better than MS/PhD status. Degree status can explain a modest amount of student score (i.e., it has a small effect on the multiple regression model's slope), but contributes fairly little in combination with E1, E2, and GPA.

## 3.

```{r}
gasd = read.table('gasd96.txt', sep = '', header = T)
gasd = gasd[2:length(gasd)]
```

### 3a.

```{r}
gasd_cor = cor(gasd[, sapply(gasd, is.numeric)])
gasd_cor
corrplot(gasd_cor)
```

Most observed correlations behave as expected. T3 and T5 scores both show strong positive correlations with T8 score (about 0.77 and 0.82, respectively). Small schools  do not seem to be associated with the best student scores, nor do medium-sized schools; correlations with T3, T5, and T8 scores are slightly stronger for large-enrollment districts than medium-enrollment, and slightly larger still for metropolitan areas, while population density is moderately positively correlated with higher scores. This seems to provide the least counter-evidence for the hypothesis that education tends to be better in urban areas, but this remains speculative. PLUN shows a strong negative correlation with all three test scores, as expected.

### 3b.

Only the pair of T3 and T5 would be disallowed.

### 3c.

```{r}
gasd_model_full = lm(T8 ~ T3 + T5 + ENRL + DENS + IMTR + IM + IL + PLUN, data = gasd)
summary(gasd_model_full)
```


